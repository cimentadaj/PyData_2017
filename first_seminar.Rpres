<style>

bold {font-weight: bold; }

.section .reveal .state-background {
    background: white;
}

.section .reveal p {
   color: black;
   text-align:center;
   font-size: 1.8em;
}

.section .reveal h1,
.section .reveal h2 {
    color: black;
    text-align:center;
    width:100%;
}

</style>

An introduction to the tidyverse
========================================================
author: Jorge Cimentada  
date: 19th of May of 2017  
class: illustration
font-family: 'Helvetica'
width: 1800
height: 900

<div align="center">
<img src="./figures/logo_tidyverse.png" width=300 height=350>
</div>

The philosophy of the tidyverse 
========================================================
incremental: true

```{r, echo = F}
knitr::opts_chunk$set(fig.width = 15)
```

- What is the tidyverse?

- "The packages in the tidyverse share a common philosophy of data and R programming, and are designed to work together naturally." R4DS

- They've been created with the same data process in mind.

Remember R packages have been created by thousands of users without a clear structure!

The tidyverse is one attempt at unifying a philosophy of data analysis.

What is the tidyverse?
=======================================================

Yeah, the tidyverse is really just a package that installs other packages:

"The tidyverse package is designed to make it easy to install and load core packages from the tidyverse in a single command." Hadley Wickham  

```{r, eval  = F}
install.packages("tidyverse")
```

What is the tidyverse?
=======================================================

What is the tidyverse for?
- It is primarily for doing data analysis and data science.

"My goal is to make the data analysis process a pit of success" Hadley Wickham

<div align="left">
<img src="./figures/data-science.png" width=1000 height=300>
</div>

<small>http://r4ds.had.co.nz/introduction.html</small>

It covers all the important steps in the data analysis workflow. You start by importing the data, this can be a well structured csv or json file or something very messy you scraped from a website. Next, you have to tidy the data, or make it suitable for analysis and then you enter the 'interactive' section of data analysis. Here there's an interplay of creating/transforming variables, visualizing interesting patterns and try to model and explain these patterns. This process gets repeated iteratively until you reach a conclusion. That is the moment we communicate our results.

What is the tidyverse?
======================================================

<div align="center">
<img src="./figures/tidyverse_pkgs.png" width=2000 height=650>
</div>

For all packages, see [here](https://github.com/tidyverse/tidyverse)

Let's get our hands dirty!
=======================================================

```{r, eval = F}
library(tidyverse)

# Loading tidyverse: readr
# Loading tidyverse: tibble
# Loading tidyverse: tidyr
# Loading tidyverse: dplyr
# Loading tidyverse: purrr
# Loading tidyverse: ggplot2
```

- These are the main packages and the ones that are loaded automatically by the tidyverse
- Today we will talk about the core tidyverse packages, ocassionaly mentioning which other packages are useful in certain situations.

Import
========================================================

```{r, echo = F}
library(tidyverse)
```

Formats:

* csv
* semi-colon delim
* text
* fixed-width-file
* json
* xml and xlsx
* databases
* etc.. see [here](https://github.com/tidyverse/tidyverse)

The usual plain-text files can be read/written with:

read_*()
write_*()

But other formats have slightly different syntax (For example, databases or jsons).

Once you're familiar with one or two read_*() functions, you're pretty much familiar with
all other read_*() functions.

Import
========================================================

```{r, echo = F}
options(tibble.print_min = 5,
        tibble.max_extra_cols = 3)
```

Let's read our toy dataset.
```{r}
url <- "https://raw.githubusercontent.com/cimentadaj/PyData_2017/master/data/police_killings.csv"
police_killings <- read_csv(url)

# More generally:
police_killings <- read_delim(url, delim = ",")
```

read_*() functions try to guess the class of each column using a set of standard parsing functions.

Several arguments are set to usual defaults:
* Column types are guessed using the first 1000 rows (problem?)
* First row is assumed to be the header
* The delimiter is set to be equal to the \* of read_*() (comma, semi-colon, etc..)
* country-specific options are set to be US-centric, as R (dates, decimal points, timezonez)

`?locale`

Tidying your data
========================================================

# Who uses data frames in R?

Data frames are, in most of the cases, the primary unit of analysis in R. It allows you to have your data in a rectangular format, with related objects occupying a row-column cell. Data frames have been around for the past 10-20 years, since S, the predecessor of R.

Tidying your data
========================================================

```{r, echo = F}
options(tibble.width = 55)
select(police_killings, name:month)
options(tibble.width = 70)
```

***

```{r, echo = F}
select(police_killings, name:month) %>%
  as.data.frame() %>%
  head(10)
```

Tidying your data
========================================================

```{r, echo = F}
options(tibble.width = 55)
select(police_killings, name:month) %>%
  print(n = 5)
options(tibble.width = 110)
```


The most obvious differences:
* Tibbles print only a reasonable number of rows (have you resarted R because of printing a massive df?)
* Each column has class printed out
* Dimensions on top of each row

Othe important differences:
* Subseting mtcars[, "mpg"] returns a tibble (no more drop = F).
* Not all functions work with tibbles, so remember to as.data.frame() your tibble

Tidying and transforming your data
========================================================
* How many Blacks were killed per state?
```{r}
# Can you understand this?
filtered_df <- filter(
    select(police_killings, state, raceethnicity),
    raceethnicity == "Black")

summarize(
  group_by(filtered_df, state),
  blacks_deaths = n())
```

Tidying and transforming your data
========================================================
* Do states with higher variance in household income (inequality) have more black deaths?
```{r}
# Can you understand this?
summarized_df <-
  arrange(
  summarize(
    group_by(police_killings, state),
    black_deaths = mean(raceethnicity == "Black", na.rm = T),
    sd_hhincome = sd(h_income, na.rm = T)),
  sd_hhincome)

top_n(summarized_df, 5, sd_hhincome)
```

The pipe
========================================================

Brief detour:

<div align="center">
<img src="./figures/pipe.png" width=800 height=530>
</div>

This is the pipe.

The pipe
============================================================

* Instead of mean(x), x %>% mean() is equivalent to mean(x)

* Just as the `|` pipe in Unix

* The pipe carries the previous result into the next function

* Best thing: you didn't have to create an object

* This mantains a logical and clean workflow

The pipe
========================================================
We could rewrite the previous as:

* How many Blacks were killed per state?
```{r, eval = F}
police_killings %>%
  select(state, raceethnicity) %>%
  filter(raceethnicity == "Black") %>%
  group_by(state) %>%
  summarize(
    black_deaths = n()
  )
```
* Do states with higher variance in household income (inequality) have more black deaths?
```{r, eval = F}
police_killings %>%
  group_by(state) %>%
  summarize(black_deaths = mean(raceethnicity == "Black", na.rm = T),
            sd_hhincome = sd(h_income, na.rm = T)) %>%
  arrange(sd_hhincome) %>%
  top_n(10, sd_hhincome)
```

Tidying and transforming your data
============================================================

`dplyr` is a package to do data manipulation.

`dplyr` contains 'verbs' which makes data manipulation very intuitive.

These are:

* Create new columns with `mutate()`
* Select variables with `select()`
* Select rows with `filter()`
* Change column names with `rename()`
* Sort by variables with `arrange()`
* Apply operations by group with `group_by()`
* Compute summary variables with `summarise()`

Delete: These functions provide the verbs for a language of data manipulation

Tidying and transforming your data
============================================================

They are so intuitive that even reading them can tell you what they do:

```{r}
police_killings %>%
  rename(ethnicity = raceethnicity) %>%
  select(gender, age, year, ethnicity, city) %>%
  mutate(year_born = age - year) %>%
  group_by(gender, ethnicity) %>%
  filter(gender == "Male") %>%
  summarise(average_age = mean(age, na.rm = T)) %>%
  arrange(average_age)
```

Can you tell what I'm doing?

Tidying and transforming your data
============================================================

Verb structure:

```{r, eval = F}

select(.data, variable_name, variable_name)

mutate(.data, new_name = contents, other_new_var = contents)

group_by(.data, variable_name, variable_name)

filter(.data, logical_statement, other_logical_statemente)

summarise(.data, new_var = contents, new_var = contets)

arrange(.data, var_to_sort_by, var_to_sort_by)
```

============================================================

# All of these functions accept and return a data frame!

Tidying and transforming your data
============================================================

Let's construct an expression ourselves.

* First, let's pipe the data frame `police_killings` and change the name of `raceethnicity` to `ethnicity` using the `rename()` verb
* Extend the pipeline to `filter()` only `Male` from `gender`
* Pipe the expression to `group_by()` the state

Tidying and transforming your data
============================================================

```{r, eval = F}
police_killings %>%
  rename(ethnicity = raceethnicity) %>%
  filter(gender == "Male") %>%
  group_by(state)
```


## What do we get back?

* Extend the pipeline by using the `summarise()` function and create the new variable `avg_black` and `avg_white` which calculates the proportion of black and white deaths for each state.
* Extend the pipeline to `arrange()` avg_black.
* Save the expression with the name `black_white_deaths`

Data transformation with dplyr
============================================================

```{r, eval = F}
black_white_deaths <-
  police_killings %>%
  rename(ethnicity = raceethnicity) %>%
  filter(gender == "Male") %>%
  group_by(state) %>%
  summarise(avg_white = mean(ethnicity == "White", na.rm = T),
            avg_black = mean(ethnicity == "Black", na.rm = T)) %>%
  arrange(avg_black)
```

```{r}
exp_data <-
  police_killings %>%
  mutate(date = zoo::as.yearmon(paste(month, year, sep = "-"), format = "%b-%Y")) %>%
  select(state, date) %>%
  complete(date, state)

exp_data %>%
  count(state, date) %>%
  mutate(n_lagged = lag(n),
         increase = n - n_lagged,
         increase = ifelse(is.na(increase), n, increase)) %>%
  ggplot(aes(date, increase, colour = state, group = state)) +
  geom_point(alpha = 0.7) +
  geom_line(alpha = 0.7) +
  scale_colour_discrete(guide = F) +
  facet_wrap(~ state) +
  xlab("Date") +
  ylab("Monthly increase in deaths relative to previous month")
```

Data transformation with dplyr
============================================================
`dplyr` also has a bunch of 'helper' functions.

For example:
* `n()`
* `lead()`
* `lag()`

## What do we get back?

Data visualization
========================================================
ggplot structure:

```{r, fig.width = 15}
ggplot(data = police_killings) +
  geom_point(mapping = aes(x = as.numeric(pov), y = pop))
```

Data visualization
========================================================

The `ggplot` function "opens" the data and the `geom` function specifies the type of plot with the variables that will be used.

The general structure is like this:

```{r, echo=T, eval = F}
ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))
```

Data visualization
========================================================

How many geoms (plots)?

- `geom_point()`
- `geom_bar()`
- `geom_histogram()`
- `geom_boxplot()`
- `geom_density()`
- `geom_line()`
- `geom_smooth()`
- And a bunch more  

[all geoms](http://sape.inf.usi.ch/quick-reference/ggplot2/geom)  
[all ggplot2 extensions](http://www.ggplot2-exts.org/gallery/)

Data visualization
========================================================

Let's look at the data again..

```{r, echo = F}
police_killings
```

Data visualization
========================================================

```{r, eval = F}
police_killings$pov <- as.numeric(police_killings$pov)
police_killings$p_income <- as.numeric(police_killings$p_income)

# colour
ggplot(data = police_killings) +
  geom_point(mapping = aes(x = pov, y = pop,
                           colour = p_income > mean(p_income, na.rm = T)))

# size
ggplot(data = police_killings) +
  geom_point(mapping = aes(x = pov, y = pop,
                           size = as.numeric(urate)))

# shape
ggplot(data = police_killings) +
  geom_point(mapping = aes(x = pov, y = pop,
                           shape = p_income > mean(p_income, na.rm = T)))

# alpha (transparency)
ggplot(data = police_killings) +
  geom_point(mapping = aes(x = pov, y = pop,
                           alpha = p_income > mean(p_income, na.rm = T)))
```

Data visualization
========================================================

All of these aesthetics can be used outside the `aes()` wrapper.

```{r, eval = F}
# colour
ggplot(data = police_killings) +
  geom_point(mapping = aes(x = pov, y = pop), colour = "blue")

# size
ggplot(data = police_killings) +
  geom_point(mapping = aes(x = pov, y = pop), size = 2.5)

# shape
ggplot(data = police_killings) +
  geom_point(mapping = aes(x = pov, y = pop), shape = 24)

# alpha (transparency)
ggplot(data = police_killings) +
  geom_point(mapping = aes(x = pov, y = pop), alpha = 0.2)
```

Data visualization
========================================================

Aesthetics vary by `geom_*()` functions so you should have a look at the documentation before using it.

- `alpha`
- `colour`
- `fill`
- `group`
- `shape`
- `size`
- `stroke`

are common ones..

Data visualization
========================================================

Let's try it out:

We want to create a scatterplot to look at the relationship between the % of black within the county and the median household income. This will help to establish whether counties with black majority are associated with lower household income.

Hints:
- x var = `as.numeric(share_black)`
- y var = `as.numeric(h_income)`
- data name = `police_killings`
- geom = `geom_point()`


Data visualization
========================================================

Answer:

```{r}
ggplot(data = police_killings) +
  geom_point(aes(x = as.numeric(share_black),
                 y = as.numeric(h_income)))
```

Data visualization
========================================================

Let's add the size of the points to be a function of the population in the county.

Hints:
- aesthetic = `size`
- variable = `pop`

Data visualization
========================================================

Answer:

```{r}
ggplot(data = police_killings) +
  geom_point(aes(x = as.numeric(share_black),
                 y = as.numeric(h_income), size = pop))
```

Too many dots! It doesn't look that nice. Let's add `alpha = 0.3`

Data visualization
========================================================

Answer:

```{r}
ggplot(data = police_killings) +
  geom_point(aes(x = as.numeric(share_black),
                 y = as.numeric(h_income),
                 size = pop),
             alpha = 0.30)
```

Data visualization
========================================================

Let's color counties based on whether they are above/below the mean unemployment rate which is 0.11:

Hint:
- aesthetic = `colour` or `color`
- variable = `as.numeric(police_killings$urate) > 0.11`

Data visualization
========================================================

Answer:

```{r}
ggplot(data = police_killings) +
  geom_point(aes(x = as.numeric(share_black),
                 y = as.numeric(h_income),
                 size = pop,
                 colour = as.numeric(police_killings$urate) > 0.11),
             alpha = 0.30)
```


Data visualization
========================================================

Let's move everything to the `ggplot()` call

```{r, eval = F}
ggplot(data = police_killings,
       aes(x = as.numeric(share_black),
                 y = as.numeric(h_income),
                 size = pop,
                 colour = as.numeric(police_killings$urate) > 0.11)) +
  geom_point(alpha = 0.30)
```


Data visualization
========================================================

Finally, let's add the a regression line for each group:

```{r}
ggplot(data = police_killings,
       aes(x = as.numeric(share_black),
           y = as.numeric(h_income),
           colour = as.numeric(police_killings$urate) > 0.11)) +
  geom_point(aes(size = pop), alpha = 0.30) +
  geom_smooth(method = "lm")
```

So much done with just a few lines!

Data visualization
========================================================

Other graphs:

```{r}
ggplot(police_killings, aes(x = age)) +
  geom_histogram(bins = 55)
```

Data visualization
========================================================

Other graphs:

```{r}
ggplot(police_killings, aes(x = raceethnicity)) +
  geom_bar()
```

Data visualization
========================================================

Other graphs:

```{r}
ggplot(police_killings, aes(x = raceethnicity, y = age)) +
  geom_boxplot()
```

Data visualization
========================================================

It's not far fetched to say that this is truly the surface of what ggplot2 can do.
To learn ggplot2:

[R graph coobook](http://www.cookbook-r.com/Graphs/)  
[ggplot2 book by its author](http://ggplot2.org/book/)  
[R for Data Science](http://r4ds.had.co.nz/)  

* But also wait for the third seminar given by Robert ;)

Data transformation with dplyr
============================================================

Here's when the strength of the `tidyverse` becomes obvious. We've used the `dplyr` tools to create a summarised dataset. This dataset is informative but we need to visualize it.

## Can you think how we can connect the dplyr tools with the ggplot tools?

Data transformation with dplyr
============================================================

This is one way of plotting the previous data.
```{r, eval = F}
ggplot(summary_police) +
  geom_col(aes(state, avg_black), fill = "blue", alpha = 0.3) +
  geom_col(aes(state, avg_white), fill = "red", alpha = 0.3) +
  coord_flip()
```

We specify the `data` name and we'll add two layers of bar graphs, one showing the proportion of black deaths and the other the proportion of white deaths for each state. Because both barplots will overlap, we add a certain degree of transparency so we can spot differences.

Data transformation with dplyr
============================================================

```{r, echo = F, fig.width = 18, fig.height = 10}
police_killings %>%
  rename(ethnicity = raceethnicity) %>%
  filter(gender == "Male") %>%
  group_by(state) %>%
  summarise(avg_white = mean(ethnicity == "White", na.rm = T),
            avg_black = mean(ethnicity == "Black", na.rm = T)) %>%
  arrange(avg_black) %>%
  ggplot() +
  geom_col(aes(state, avg_black), fill = "blue", alpha = 0.3) +
  geom_col(aes(state, avg_white), fill = "red", alpha = 0.3) +
  coord_flip()
```

Data transformation with dplyr
============================================================

How do we connect both expressions?

## The PIPE at the rescue

Data transformation with dplyr
============================================================

```{r, eval = F}
police_killings %>%
  rename(ethnicity = raceethnicity) %>%
  filter(gender == "Male") %>%
  group_by(state) %>%
  summarise(avg_white = mean(ethnicity == "White", na.rm = T),
            avg_black = mean(ethnicity == "Black", na.rm = T)) %>%
  arrange(avg_black) %>%
  ggplot() +
  geom_col(aes(state, avg_black), fill = "blue", alpha = 0.3) +
  geom_col(aes(state, avg_white), fill = "red", alpha = 0.3) +
  coord_flip()
```

Benefits of this workflow:
- Intuitive verb names
- Easy to read from left to right
- No OBJECTS were created in the process
- Allows you to think about your questions rather than on programming


Data import with haven and readr
============================================================

```{r, eval = F}
library(readr)
library(haven)
library(readxl)

read_csv() # CSV, comma delimited
read_stata() # Stata file: supports versions 8-14.
read_spss() # SPSS (.sav) files
read_sas() # SAS files
read_excel() # Read .xls or .xlsx
```

Data import with haven and readr
============================================================

- Package DBI (e.g. RMySQL, RSQLite, RPostgreSQL etc) allows you to run SQL queries against a database and return a data frame.

- For hierarchical data: use `jsonlite` (by Jeroen Ooms) for json, and `xml2` for XML. Jenny Bryan has some excellent worked examples at https://jennybc.github.io/purrr-tutorial/examples.html.

Data import with haven and readr
============================================================

```{r}
library(readr)
dir_link <- "https://raw.githubusercontent.com/fivethirtyeight/data/master/police-killings/police_killings.csv"

police_killings <- read_csv(dir_link)
```

Let's put everything together
============================================================

```{r, eval = F}
library(tidyverse)
library(readr)

dir_link <- "https://raw.githubusercontent.com/fivethirtyeight/data/master/police-killings/police_killings.csv"

police_killings <- read_csv(dir_link)

police_killings %>%
  rename(ethnicity = raceethnicity) %>%
  filter(gender == "Male") %>%
  group_by(state) %>%
  summarise(avg_white = mean(ethnicity == "White", na.rm = T),
            avg_black = mean(ethnicity == "Black", na.rm = T)) %>%
  arrange(avg_black) %>%
  ggplot() +
  geom_col(aes(state, avg_black), fill = "blue", alpha = 0.3) +
  geom_col(aes(state, avg_white), fill = "red", alpha = 0.3) +
  coord_flip()
```

Rstudio workflow
============================================================

Yes, HOMEWORK:
http://r4ds.had.co.nz/workflow-projects.html

============================================================

# Thanks!
## cimentadaj@gmail.com
- If you want to be in our mailing list
- Also, send feedback or want to propose a lecture/seminar

<div align="center">
<img src="./figures/tidyverse_pkg_stickers.png" width=800 height=530>
</div>